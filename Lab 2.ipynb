{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2: Armado de un esquema de aprendizaje automático\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Documentación:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responder las siguientes preguntas:\n",
    "\n",
    "1. ¿De qué se trata el conjunto de datos?\n",
    "2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?\n",
    "3. ¿Qué información (atributos) hay disponible para hacer la predicción?\n",
    "4. ¿Qué atributos imagina ud. que son los más determinantes para la predicción?\n",
    "\n",
    "**No hace falta escribir código para responder estas preguntas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - The dataset consists of a data related to banking and loan review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - The variable ```TARGET``` is a boolean that identifies if the prospective bank lender has thier loan approved or not. The value ```1``` represents approved and ```0``` not approved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - The features available for this are things such as the mortgage, the value of the loan ```LOAN```, whether the lender has been delinquent ```DELINQ```, debt incurred ```DEBTINC```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENT DENIED: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "selector = (dataset['TARGET'] == 0)\n",
    "print(\"PERCENT DENIED:\",dataset[selector].shape[0] / dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\n"
     ]
    }
   ],
   "source": [
    "features = dataset.columns.to_list()\n",
    "features.remove('TARGET')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - We guess that the size of the loan ```LOAN``` and the past delinquency ```DEBTINC``` will affect the outcome of the loan application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Predicción con Modelos Lineales\n",
    "\n",
    "En este ejercicio se entrenarán modelos lineales de clasificación para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase SGDClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador SGDClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(random_state=4)#semilla\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.8355795148247979\n",
      "PREC 0.0\n",
      "RECALL 0.0\n",
      "F1 0.0\n",
      "CONFUSION MATRIX:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[310,   3],\n",
       "       [ 58,   0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "print(\"ACC:\",accuracy_score(y_test, y_pred))\n",
    "print(\"PREC\",precision_score(y_test, y_pred))\n",
    "print(\"RECALL\",recall_score(y_test, y_pred))\n",
    "print(\"F1\",f1_score(y_test, y_pred)) \n",
    "print('CONFUSION MATRIX:')\n",
    "confusion_matrix(y_test, y_pred) # there are NO true negatives!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion matrix](images/confusion_matrix.png \"confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem: Because there are so few training examples it is difficult to have a meaningful model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del SGDClassifier. Como mínimo, probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of each fold: [0.82210243 0.8328841  0.8328841  0.74393531 0.82972973]\n",
      "Mean accuracy of all of the folds: 0.8123071319297734\n",
      "Standard Deviation of accuracies: 0.03441227606875618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Accuracy of each fold:\",cross_val_score(clf, X, y, cv=5))\n",
    "print(\"Mean accuracy of all of the folds:\",cross_val_score(clf, X, y, cv=5).mean())\n",
    "#print(cross_val_score(clf, X, y, cv=5).var())\n",
    "print(\"Standard Deviation of accuracies:\",cross_val_score(clf, X, y, cv=5).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'loss' : ['hinge', 'log', 'perceptron', 'modified_huber', 'squared_hinge'],\n",
    "    'penalty' : ['l2', 'l1', 'elasticnet'], \n",
    "    'learning_rate' : ['constant','optimal','invscaling','adaptive'],\n",
    "    'eta0' : [0.1,0.2,0.4,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = GridSearchCV(clf, param_grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.780475</td>\n",
       "      <td>0.074753</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.805286</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_loss param_penalty param_eta0  mean_test_score  std_test_score  \\\n",
       "0      hinge            l2        0.1         0.780475        0.074753   \n",
       "1      hinge            l1        0.1         0.833333        0.000000   \n",
       "2      hinge    elasticnet        0.1         0.831176        0.003051   \n",
       "3        log            l2        0.1         0.831176        0.003051   \n",
       "4        log            l1        0.1         0.805286        0.027151   \n",
       "\n",
       "   rank_test_score  \n",
       "0              138  \n",
       "1                1  \n",
       "2               30  \n",
       "3               30  \n",
       "4              121  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cv.cv_results_\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_loss', 'param_penalty','param_eta0', 'mean_test_score', 'std_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'penalty': 'l1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find the average and variance of all of the scores\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.82\n",
      "PREC 0.17\n",
      "RECALL 0.03\n",
      "F1 0.06\n",
      "CONFUSION MATRIX:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[303,  10],\n",
       "       [ 56,   2]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the best configuration report\n",
    "clf = SGDClassifier(random_state=4, eta0= 0.1, learning_rate='constant',loss='hinge',penalty='l1')#semilla\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "print(\"ACC:\",accuracy_score(y_test, y_pred).round(2))\n",
    "print(\"PREC\",precision_score(y_test, y_pred).round(2))\n",
    "print(\"RECALL\",recall_score(y_test, y_pred).round(2))\n",
    "print(\"F1\",f1_score(y_test, y_pred).round(2)) # Voila! magically we now have precision and recall!\n",
    "print('CONFUSION MATRIX:')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentary:\n",
    "    Still no precision or recall but the accuracy has increased marginally after hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion matrix](images/confusion_matrix.png \"confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n",
    "\n",
    "En este ejercicio se entrenarán árboles de decisión para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase DecisionTreeClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "  - https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador DecisionTreeClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy : 0.88\n",
      "Test precision: 0.62\n",
      "Test recall   : 0.64\n",
      "Test f1 score : 0.63\n",
      "CONFUSION MATRIX:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[310,   3],\n",
       "       [ 58,   0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "prec_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "print(f'Train accuracy: {train_acc:0.2}')\n",
    "print(f'Test accuracy : {test_acc:0.2}')\n",
    "print(f'Test precision: {prec_test:0.2}')\n",
    "print(f'Test recall   : {recall_test:0.2}')\n",
    "print(f'Test f1 score : {f1_test:0.2}')\n",
    "print('CONFUSION MATRIX:')\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion matrix](images/confusion_matrix.png \"confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del DecisionTreeClassifier. Como mínimo, probar diferentes criterios de partición (criterion), profundidad máxima del árbol (max_depth), y cantidad mínima de samples por hoja (min_samples_leaf).\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of each fold: [0.8328841  0.8328841  0.8490566  0.86522911 0.87297297]\n",
      "Mean accuracy of all of the folds: 0.8506053762657537\n",
      "Standard Deviation of accuracies: 0.016399080200692626\n"
     ]
    }
   ],
   "source": [
    "#kf = KFold(n_splits=5, shuffle=False, random_state=0)\n",
    "print(\"Accuracy of each fold:\",cross_val_score(clf, X, y, cv=5))\n",
    "print(\"Mean accuracy of all of the folds:\",cross_val_score(clf, X, y, cv=5).mean())\n",
    "#print(cross_val_score(clf, X, y, cv=5).var())\n",
    "print(\"Standard Deviation of accuracies:\",cross_val_score(clf, X, y, cv=5).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf' : [1,2,3,4,5,6,7,8,9,10],\n",
    "    'criterion' : ['gini', 'entropy'], \n",
    "    'max_depth' : [1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(clf, param_grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87109</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.87109</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>0.87109</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>0.87109</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.87109</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth param_criterion param_min_samples_leaf  mean_test_score  \\\n",
       "0               1            gini                      1          0.87109   \n",
       "1               1            gini                      2          0.87109   \n",
       "2               1            gini                      3          0.87109   \n",
       "3               1            gini                      4          0.87109   \n",
       "4               1            gini                      5          0.87109   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.013234                7  \n",
       "1        0.013234                7  \n",
       "2        0.013234                7  \n",
       "3        0.013234                7  \n",
       "4        0.013234                7  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cv.cv_results_\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_max_depth', 'param_criterion','param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 9}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.87\n",
      "Test accuracy : 0.88\n",
      "Test precision: 0.85\n",
      "Test recall   : 0.29\n",
      "Test f1 score : 0.44\n",
      "CONFUSION MATRIX:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[310,   3],\n",
       "       [ 58,   0]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=2, min_samples_leaf=9,random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "prec_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "print(f'Train accuracy: {train_acc:0.2}')\n",
    "print(f'Test accuracy : {test_acc:0.2}')\n",
    "print(f'Test precision: {prec_test:0.2}')\n",
    "print(f'Test recall   : {recall_test:0.2}')\n",
    "print(f'Test f1 score : {f1_test:0.2}')\n",
    "print('CONFUSION MATRIX:')\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.3: Inspección del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge of this dataset was that the binary target feature, approval or disapproval of a loan, was greatly weighted towards disapproval; less than 20 percent of the training samples were of loan cases that were approved. In cases like this a data scientist runs the risk of building a model that always gives the same answer, the category that has the majority of the \"votes\" from the training data. In that way, this example is good to show the advantages and, in some cases, necessities to perform the tecniques Grid Search and Cross Validation as a preparation for designing the architeqcture and training specifications for your machine learning model, especially in the case of classification data that is imbalanced or weighted particularly towards one class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
